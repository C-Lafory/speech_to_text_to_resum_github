version: '3.8'

services:
  # Service Ollama
  ollama:
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    environment:
      - OLLAMA_HOST=0.0.0.0
      - OLLAMA_ORIGINS=*
    command: serve

  # Service principal (Python 3.12)
  main_api:
    build:
      context: ./backend_python
      dockerfile: Dockerfile.main
    ports:
      - "8000:8000"
    volumes:
      - ./backend_python:/app
      - ./models:/app/models
    environment:
      - PYTHONPATH=/app
      - TTS_MODEL_PATH=/app/models/tts
      - WHISPER_MODEL_PATH=/app/models/whisper
      - SPACY_MODEL_PATH=/app/models/spacy
      - MAIN_API_PORT=8000
      - OLLAMA_HOST=ollama
      - OLLAMA_PORT=11434
    depends_on:
      - ollama
    command: bash -c "chmod +x /app/init_main.sh && bash /app/init_main.sh"
    networks:
      - app_network

  # Service TTS (Python 3.10)
  tts_service:
    build:
      context: ./backend_python
      dockerfile: Dockerfile.tts
    ports:
      - "8001:8001"
    volumes:
      - ./backend_python:/app
      - ./models:/app/models
    environment:
      - PYTHONPATH=/app
      - TTS_MODEL_PATH=/app/models/tts
      - TTS_API_PORT=8001
    command: bash -c "chmod +x /app/init_tts.sh && bash /app/init_tts.sh"
    networks:
      - app_network

networks:
  app_network:
    driver: bridge

volumes:
  ollama_data:
    driver: local 