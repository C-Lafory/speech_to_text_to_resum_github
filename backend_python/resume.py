import os
import sys
import logging
import spacy
import ollama
import gc
from download_models import SPACY_MODEL

# Configuration des chemins
BASE_DIR = "static/file"
RESUME_FILENAME = "resum.txt"
TRANSCRIPTION_FILENAME = "transcription.txt"
MIN_CHUNK_SIZE = 512
MAX_CHUNK_SIZE = 2048
TARGET_CHUNK_SIZE = 1024

# Logger
logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")

# Initialiser Spacy avec le mod√®le pr√©charg√©
try:
    nlp = spacy.load(SPACY_MODEL)
except OSError:
    logging.error(f"‚ùå Mod√®le Spacy ({SPACY_MODEL}) non trouv√©. Ex√©cutez d'abord download_models.py")
    sys.exit(1)

def count_tokens(text: str) -> int:
    return len(nlp(text))

def calculate_optimal_chunk_size(text: str) -> int:
    """Calcule la taille optimale des chunks en fonction de la longueur du texte"""
    total_tokens = count_tokens(text)
    if total_tokens < MIN_CHUNK_SIZE:
        return total_tokens
    elif total_tokens > MAX_CHUNK_SIZE * 10:  # Pour les tr√®s longs textes
        return MAX_CHUNK_SIZE
    else:
        return min(max(MIN_CHUNK_SIZE, total_tokens // 10), MAX_CHUNK_SIZE)

def split_text(text: str) -> list[str]:
    """Divise le texte en chunks de taille optimale"""
    chunk_size = calculate_optimal_chunk_size(text)
    sections = []
    start = 0
    
    while start < len(text):
        end = min(start + chunk_size, len(text))
        # Chercher le dernier point ou la derni√®re virgule dans la fen√™tre
        last_dot = text.rfind('.', start, end)
        last_comma = text.rfind(',', start, end)
        last_break = max(last_dot, last_comma)
        
        if last_break != -1:
            end = last_break + 1
        sections.append(text[start:end].strip())
        start = end
    
    return sections

def summarize_chunk(chunk: str) -> str:
    try:
        response = ollama.chat(model="mistral:7b", messages=[
            {"role": "system", "content": "Tu es un expert en r√©sum√© de texte en fran√ßais."},
            {"role": "user", "content": (
                "Fais un r√©sum√© d√©taill√© de ce texte en incluant toutes les informations importantes, "
                "y compris les noms propres, dates, chiffres et mots-cl√©s. Le r√©sum√© doit faire environ 25% du texte original "
                f"et il doit √™tre en fran√ßais : {chunk}"
            )}
        ])
        return response.get("message", {}).get("content", "")
    except Exception as e:
        logging.error(f"‚ùå Erreur lors de l'utilisation d'Ollama : {e}")
        raise RuntimeError("Erreur avec Ollama. V√©rifiez que le mod√®le mistral:7b est bien install√© via download_models.py")

def summarize_file(input_path: str, output_path: str):
    logging.info(f"üìÑ Lecture de {input_path}")
    with open(input_path, "r", encoding="utf-8") as f:
        text = f.read()

    token_count = count_tokens(text)
    logging.info(f"üìä {token_count} tokens d√©tect√©s.")

    if token_count < 500:
        logging.info("üîπ Texte trop court, pas de r√©sum√© g√©n√©r√©.")
        with open(output_path, "w", encoding="utf-8") as f:
            f.write(text)
        return

    chunks = split_text(text)
    logging.info(f"üß© {len(chunks)} morceaux √† r√©sumer")

    summaries = []
    for idx, chunk in enumerate(chunks):
        try:
            logging.info(f"üìù R√©sum√© du chunk {idx + 1}/{len(chunks)}")
            summary = summarize_chunk(chunk)
            summaries.append(summary)
            # Nettoyage de la m√©moire apr√®s chaque chunk
            gc.collect()
        except Exception as e:
            logging.error(f"‚ùå √âchec du r√©sum√© du chunk {idx + 1} : {e}")

    final_summary = "\n".join(summaries)
    with open(output_path, "w", encoding="utf-8") as f:
        f.write(final_summary)
    logging.info(f"‚úÖ R√©sum√© g√©n√©r√© dans {output_path}")

def main():
    if len(sys.argv) != 2:
        logging.error("‚ùå Usage : python summarizer.py <user_id>")
        sys.exit(1)

    user_id = sys.argv[1]
    user_dir = os.path.join(BASE_DIR, user_id)
    input_file = os.path.join(user_dir, TRANSCRIPTION_FILENAME)
    output_file = os.path.join(user_dir, RESUME_FILENAME)

    if not os.path.isfile(input_file):
        logging.error(f"‚ùå Fichier de transcription introuvable : {input_file}")
        sys.exit(2)

    try:
        summarize_file(input_file, output_file)
    except Exception as e:
        logging.error(f"üö® Erreur lors du r√©sum√© : {e}")
        sys.exit(3)

if __name__ == "__main__":
    main()
